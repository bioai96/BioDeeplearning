{"cells":[{"cell_type":"code","source":[""],"metadata":{"id":"hSHgBvsoRzi3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 드라이브 마운트 및 공유 디렉토리 설정"],"metadata":{"id":"VdzxKdvUiP11"}},{"cell_type":"code","source":["# drive mount\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2u58OHVpTYRr","outputId":"7fe334a9-6877-4d0c-93ff-bc3caef38389"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 7강 공유 폴더 \n","\n","data_path = '/content/drive/MyDrive/For_studuent_sharing/7강/data/processed.h5'"],"metadata":{"id":"NXL-eVTEUJBF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 준비 (Data preparation)"],"metadata":{"id":"pGGb6xipR3bn"}},{"cell_type":"markdown","source":["### 데이터 살펴보기 \n","\n","---\n","\n","**Raw data source**  \n","Drug-like commercially available molecules from ZINC database.  \n","https://zinc.docking.org/\n","\n","\n"],"metadata":{"id":"bss-JETJCeQ7"}},{"cell_type":"code","source":["import h5py\n","h5f = h5py.File(data_path, 'r')"],"metadata":{"id":"v0TYSxNcSXTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pre-processed(one-hot encoded) molecule data \n","\n","data_train = h5f['data_train'][:]\n","data_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlKIJ_nbCo-J","outputId":"33631d82-cd33-419d-ce58-453c2e69675d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40000, 120, 33)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["\n","- Sample size: 40000  \n","- Max sequence length: 120   \n","- Number of characters: 33\n"],"metadata":{"id":"aHtXF5qmHrZZ"}},{"cell_type":"code","source":["# One-hot encoding에 사용된 characters \n","\n","h5f['charset'][:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3omsaXFFr_p","outputId":"f3920837-6b40-45ba-e626-4f42bbde3404"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b' ', b'#', b')', b'(', b'+', b'-', b'/', b'1', b'3', b'2', b'5',\n","       b'4', b'7', b'6', b'=', b'@', b'C', b'B', b'F', b'I', b'H', b'O',\n","       b'N', b'S', b'[', b']', b'\\\\', b'c', b'l', b'o', b'n', b's', b'r'],\n","      dtype='|S1')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 샘플 하나 예시\n","x_example = data_train[:8]\n","x_example.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1Lqi_HED048","outputId":"6efc9582-860e-4b05-f382-02292a65c762"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8, 120, 33)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["data_test = h5f['data_test'][:]\n","data_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDCVIKVWCqbG","outputId":"addeed3d-9914-413b-90e5-120df5c0657c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 120, 33)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["- Sample size: 10000  \n","- Max sequence length: 120   \n","- Number of characters: 33"],"metadata":{"id":"3f_taKMoMXDS"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"5FR_Y8iqpwFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습 (Training)"],"metadata":{"id":"fiFNkyHphPOs"}},{"cell_type":"markdown","source":["### 학습에 필요한 함수 정의"],"metadata":{"id":"Bhzhw9OaLzaq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZ7Cl9tzTCl-"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aXdqRqQTLEX"},"outputs":[],"source":["\n","def from_one_hot_array(vec): \n","    oh = np.where(vec == 1)\n","    if oh[0].shape == (0, ):\n","        return None\n","    return int(oh[0][0])\n","\n","def decode_smiles_from_indexes(vec, charset):\n","    \"\"\"숫자 index를 character로 바꾸기\n","    \"\"\"\n","    return \"\".join(map(lambda x: charset[x], vec)).strip()\n","\n","def load_dataset(filename, split = True):\n","    \"\"\"데이터 불러오기 \n","\n","    Args:\n","        filename (str): 전처리 된 h5py 파일이 저장된 경로\n","        split (bool): If True; train과 test 데이터 모두 반환. else; test만 반환\n","\n","    Returns:\n","        tuple: data와 charset  \n","    \"\"\"\n","\n","    # 전처리 된 데이터 불러오기\n","    h5f = h5py.File(filename, 'r')\n","    \n","    # Train / Test data 나누기\n","    if split:\n","        data_train = h5f['data_train'][:]\n","    else:\n","        data_train = None\n","    data_test = h5f['data_test'][:]\n","\n","    # molecule characters \n","    charset =  h5f['charset'][:]\n","    h5f.close()\n","\n","    if split:\n","        return (data_train, data_test, charset)\n","    else:\n","        return (data_test, charset)\n"]},{"cell_type":"markdown","source":["### Data loading "],"metadata":{"id":"tG-H_HNxp9Af"}},{"cell_type":"code","source":["# 데이터 불러오기 \n","data_train, data_test, charset = load_dataset(data_path)\n","charset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVo0bG8fp7C2","outputId":"ceff5e21-bc01-4027-83c6-ff3a92f95e9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b' ', b'#', b')', b'(', b'+', b'-', b'/', b'1', b'3', b'2', b'5',\n","       b'4', b'7', b'6', b'=', b'@', b'C', b'B', b'F', b'I', b'H', b'O',\n","       b'N', b'S', b'[', b']', b'\\\\', b'c', b'l', b'o', b'n', b's', b'r'],\n","      dtype='|S1')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["charset = [char.decode('utf-8') for char in charset]\n","print(charset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFJlAbeEqSnW","outputId":"c679598d-1c8a-42d6-b580-d4fb00a1a4fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' ', '#', ')', '(', '+', '-', '/', '1', '3', '2', '5', '4', '7', '6', '=', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'S', '[', ']', '\\\\', 'c', 'l', 'o', 'n', 's', 'r']\n"]}]},{"cell_type":"markdown","source":["### Torch Dataset 및 DataLoader"],"metadata":{"id":"5iOvm47wqJOK"}},{"cell_type":"code","source":["# Torch Dataset \n","data_train = torch.utils.data.TensorDataset(torch.from_numpy(data_train))\n","\n","# Torch DataLoader\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=250, shuffle=True)"],"metadata":{"id":"glQSra8kqPM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_loader:\n","    x_example = batch[0]\n","    print(x_example.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpyI5XyvqV9f","outputId":"df21ffb5-ed22-42fd-8fc9-322e2f5fe3c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([250, 120, 33])\n"]}]},{"cell_type":"markdown","source":["### Variational AutoEncoder(VAE) 모델 만들기\n","\n","---\n","\n","![](https://drive.google.com/uc?export=view&id=1VImMz5Zo0dv1mu5NZ7Q_a-DBmGUTGOHz)\n"],"metadata":{"id":"OTctVCk3Y4XS"}},{"cell_type":"code","source":["# 필요한 라이브러리 호출\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data\n","import torch.optim as optim"],"metadata":{"id":"14FG07vfRH_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGAirp3UUDmt"},"outputs":[],"source":["class MolecularVAE(nn.Module):\n","    \"\"\"Molecule 생성을 위한 VAE 모델\n","    \"\"\"\n","    def __init__(self):\n","        super(MolecularVAE, self).__init__()\n","\n","        # encoding을 위한 1D-convolution layer과 linear layer\n","        self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n","        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n","        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n","        self.linear_0 = nn.Linear(70, 435)\n","        \n","        # Latent variables을 생성하는 layers\n","        self.linear_1 = nn.Linear(435, 292) # mean\n","        self.linear_2 = nn.Linear(435, 292) # variance\n","\n","        # decoding을 위한 GRU layer과 linear layer\n","        self.linear_3 = nn.Linear(292, 292)\n","        self.gru = nn.GRU(292, 501, 3, batch_first=True)\n","        self.linear_4 = nn.Linear(501, 33)\n","        \n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax()\n","\n","    def encode(self, x):\n","        \"\"\"Input을 encoding 해서 latent variables 추정\n","\n","        Returns:\n","            tuple: latent variables (mean, log tranfromed variance)\n","        \"\"\"\n","        # 1D-convolution\n","        x = self.relu(self.conv_1(x))                   # (batch_size, 9, 25)\n","        x = self.relu(self.conv_2(x))                   # (batch_size, 9, 17)\n","        x = self.relu(self.conv_3(x))                   # (batch_size, 10, 7)\n","\n","        # flatten\n","        x = x.view(x.size(0), -1)                       # (batch_size, 70)\n","\n","        # Linear embedding\n","        x = F.selu(self.linear_0(x))                    # (batch_size, 435)\n","\n","        # Latent variable을 생성하는 linear embedding \n","        z_mean = self.linear_1(x)                       # (batch_size, 292)\n","        # 학습 안정성을 위해 log transform한 분산을 추정\n","        z_logvar = self.linear_2(x)                     # (batch_size, 292)\n","        return z_mean, z_logvar\n","\n","    def sampling(self, z_mean, z_logvar):\n","        \"\"\"Reparametrization Trick \n","        N(0,1)의 정규분포에서 랜던 샘플링한 epsilon 값을 sigam에 곱한 뒤 mean에 더하기\n","\n","        sigma는 항상 양수 값을 가지므로 학습 안정성을 위해 실제 구현 시에는 log(var)을 추정한 뒤 \n","        'sigma = exp(0.5 * log(var))' 와 같이 sigma를 구함 \n","        \n","        https://stats.stackexchange.com/questions/486158/reparameterization-trick-in-vaes-how-should-we-do-this\n","        \"\"\"\n","        # N(0,1)에서 랜덤 샘플링 \n","        epsilon = 1e-2 * torch.randn_like(z_logvar) \n","        # log(var) -> sigma\b\n","        sigma = torch.exp(0.5 * z_logvar)\n","        # random sampling 된 z\n","        z = sigma * epsilon + z_mean\n","        return z\n","\n","    def decode(self, z):\n","        \"\"\"Random sampling 한 z 값으로 molecule generation\n","        \"\"\"\n","        # random sampling 된 z를 linear embedding\n","        z = F.selu(self.linear_3(z))                        # (batch_size, 292)\n","        z = z.view(z.size(0), 1, z.size(-1))                # (batch_size, 1, 292)\n","        z = z.repeat(1, 120, 1)                             # (batch_size, sequence length(120), 292)\n","\n","        # layer 3개의 GRU\n","        z, hn = self.gru(z)                                 # (batch_size, sequence length(120), 501), (1, 501)\n","        _b = z.size(0)\n","        z = z.contiguous().view(-1, z.size(-1))             # (batch_size x sequence length(120), 501)\n","\n","\n","        # contiguous -> https://inhyeokyoo.github.io/pytorch/contiguous/\n","        # contiguous -> https://f-future.tistory.com/entry/Pytorch-Contiguous\n","        # contiguous -> https://jimmy-ai.tistory.com/122\n","\n","        \n","        # linear embedding \n","        # character dimension(33차원)으로 만들기\n","        z = self.linear_4(z)                                # (batch_size x sequence length(120), 33)\n","        \n","        # 33개 character에 대한 확률 값으로 만들기\n","        z = F.softmax(z, dim=1)\n","\n","        x_decoded = z.contiguous().view(_b, -1, z.size(-1)) # (batch_size, sequence length(120), 33)\n","        return x_decoded\n","\n","    def forward(self, x):\n","        # Encoding\n","        z_mean, z_logvar = self.encode(x)\n","        # Random sampling (reparametrization trick)\n","        z = self.sampling(z_mean, z_logvar)\n","        # Decoding\n","        x_decoded = self.decode(z)\n","        return x_decoded, z_mean, z_logvar"]},{"cell_type":"markdown","source":["### VAE toy example"],"metadata":{"id":"UVOHlt-ooyXs"}},{"cell_type":"code","source":["# Toy \n","x = x_example\n","vae = MolecularVAE()"],"metadata":{"id":"5F2KmbwNox0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoding \n","mean, var = vae.encode(x)\n","print(mean.shape)\n","print(var.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBBPu3l-sW0k","outputId":"9dfd9d54-595f-44a4-afdc-a81a954500cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([250, 292])\n","torch.Size([250, 292])\n"]}]},{"cell_type":"code","source":["# random sampling (Reparametrization trick)\n","z = vae.sampling(mean, var)\n","print(z.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bn1DcVtMsxAa","outputId":"23d0b83e-bdc6-4a82-f02e-19a68ceb2c89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([250, 292])\n"]}]},{"cell_type":"code","source":["# Decoding\n","x_decoded = vae.decode(z)\n","print(x_decoded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pTxrjXIsWED","outputId":"81604048-b126-4c5f-836f-dbaeabb34570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([250, 120, 33])\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D278asI_Vn-H"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["### 학습을 위한 설정"],"metadata":{"id":"UeBi4lxFay4l"}},{"cell_type":"code","source":["# random seed 고정하기\n","torch.manual_seed(42)\n","\n","# 학습 epoch 수 \n","epochs = 50\n","\n","# Device 설정 \n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'현재 device: {device}')\n","\n","# 모델 선언하기\n","model = MolecularVAE().to(device)\n","\n","# \boptimizer  \n","optimizer = optim.Adam(model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahksvtL0_cwV","outputId":"d8524e67-8c3c-4f41-f36d-90afa3389304"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 device: cuda\n"]}]},{"cell_type":"markdown","source":["### 학습 진행"],"metadata":{"id":"YGFd0pxIbFNw"}},{"cell_type":"markdown","source":["VAE 학습을 위한 loss 정의\n","\n","---\n","\n","\n","![](https://drive.google.com/uc?export=view&id=19ANgkmP6I-fqasKaVV4RYkMvX1l3YHLJ)\n"],"metadata":{"id":"JruNnL1Iby96"}},{"cell_type":"code","source":["def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n","    \"\"\"VAE loss 계산\n","    \"\"\"    \n","    # Reconstruction loss\n","    xent_loss = F.binary_cross_entropy(x_decoded_mean, x, size_average=False)\n","\n","    # Regularization\n","    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n","    \n","    return xent_loss + kl_loss"],"metadata":{"id":"Y7eJedQNcA74"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5r0gV2l-AtAS"},"outputs":[],"source":["\n","\n","def train(epoch):\n","    \"\"\"모델 학습\n","    \"\"\"\n","    model.train()\n","    train_loss = 0\n","    for batch_idx, data in enumerate(train_loader):\n","        data = data[0].to(device)\n","        \n","        # forward-pass\n","        output, mean, logvar = model(data)\n","        \n","        # 데이터 예시\n","        if batch_idx==0:\n","            inp = data.cpu().numpy()\n","            outp = output.cpu().detach().numpy()\n","            lab = data.cpu().numpy()\n"," \n","            print(\"Input:\")\n","            print(inp)\n","            print(decode_smiles_from_indexes(map(from_one_hot_array, inp[0]), charset))\n","\n","            print(\"Label:\")\n","            print(decode_smiles_from_indexes(map(from_one_hot_array, lab[0]), charset))\n","            sampled = outp[0].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n","\n","            print(\"Output:\")\n","            print(decode_smiles_from_indexes(sampled, charset))\n","        \n","        loss = vae_loss(output, data, mean, logvar)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        train_loss += loss\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'{epoch} / {batch_idx}\\t{loss:.4f}')\n","\n","    print('train', train_loss / len(train_loader.dataset))\n","    return train_loss / len(train_loader.dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HiDKCdauDqUh","outputId":"4086b2fc-18ad-4130-9bbf-ad2d1a523963"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," ...\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]]\n","c1ccc(cc1)CS(=O)(=O)NCc2ccccn2\n","Label:\n","c1ccc(cc1)CS(=O)(=O)NCc2ccccn2\n","Output:\n","rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["1 / 0\t133759.0156\n","1 / 100\t31155.8184\n","train tensor(149.7125, device='cuda:0', grad_fn=<DivBackward0>)\n","Input:\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," ...\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]]\n","CC(=O)c1ccc(cc1)OCC(=O)OC\n","Label:\n","CC(=O)c1ccc(cc1)OCC(=O)OC\n","Output:\n","CccccccccccccccccccccccccccccccC\n","2 / 0\t37659.2109\n","2 / 100\t31245.3203\n","train tensor(123.6251, device='cuda:0', grad_fn=<DivBackward0>)\n","Input:\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," ...\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]]\n","Cc1ccc(cc1)n2c(c(c3c2ccc(c3)O)C(=O)C)C\n","Label:\n","Cc1ccc(cc1)n2c(c(c3c2ccc(c3)O)C(=O)C)C\n","Output:\n","CcccccccccccccccccccccccccccccccccccC\n","3 / 0\t29624.6035\n","3 / 100\t30690.5508\n","train tensor(118.8870, device='cuda:0', grad_fn=<DivBackward0>)\n","Input:\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," ...\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]]\n","Cc1nc(cs1)c2nc(cc(n2)OC)COC\n","Label:\n","Cc1nc(cs1)c2nc(cc(n2)OC)COC\n","Output:\n","C1cccccccccccccccccccccc)C\n","4 / 0\t28885.8164\n","4 / 100\t30008.8125\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-ff7094bc1b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-62-310932cb24a8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward-pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 학습 진행\n","for epoch in range(1, epochs + 1):\n","    train_loss = train(epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oN00ZPZjDqWo"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["# Molecule generation "],"metadata":{"id":"O6DQIAH4cr6A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qL_NFL6lDBMX"},"outputs":[],"source":["# Gaussian 분포에서 random sampling\n","z = torch.randn(64, 292).cuda()\n","\n","# random sampling된 z로 molecule generation\n","sample = model.decode(z).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6Tx_fyEDCTK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f0023f8-8a4c-4a68-c372-60575ed9e176"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 120, 33])"]},"metadata":{},"execution_count":65}],"source":["sample.shape"]},{"cell_type":"code","source":["outp = sample.cpu().detach().numpy()\n","outp[10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_70pq6LWe0I-","outputId":"b8873871-da34-4e0b-cb13-c6d0f7c10c64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[9.1399340e-04, 5.0477032e-04, 3.1022017e-03, ..., 4.4673006e-03,\n","        8.0889853e-04, 2.3443282e-04],\n","       [4.8638755e-04, 3.2591890e-04, 4.7977935e-03, ..., 9.1953501e-03,\n","        9.9231524e-04, 1.3034025e-04],\n","       [4.3968740e-04, 3.2560879e-04, 9.5880041e-03, ..., 1.1825797e-02,\n","        1.5764314e-03, 1.1669738e-04],\n","       ...,\n","       [9.9987209e-01, 2.4397045e-06, 1.0256973e-05, ..., 1.0649267e-06,\n","        1.0975990e-06, 4.5960915e-06],\n","       [9.9987221e-01, 2.4394603e-06, 1.0253043e-05, ..., 1.0645033e-06,\n","        1.0970655e-06, 4.5938923e-06],\n","       [9.9987233e-01, 2.4392186e-06, 1.0249153e-05, ..., 1.0640874e-06,\n","        1.0965373e-06, 4.5917072e-06]], dtype=float32)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QozBZCHODVTS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5843f2e-5e0e-4500-e4ce-98e4df9dd6d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([16,  7, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n","       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 16, 16,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0])"]},"metadata":{},"execution_count":67}],"source":["# # Generation 된 molecule의 11번째 charcter index 구하기\n","sampled = outp[10].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n","sampled"]},{"cell_type":"code","source":["# index -> character\n","decode_smiles_from_indexes(sampled, charset)"],"metadata":{"id":"Lj_RIuJVe7Z7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqrQrbJCDzVE"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJ5aFzchTSH9"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FbbVCQ2Wo7Y"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpTZocmaCq5Y"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"7강_Molecular_VAE_Generation_ver5_cook.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}